{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07312329-66a4-45fe-a93b-02fceec1a738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T14:14:37.440079Z main ERROR Reconfiguration failed: No configuration found for '567d299b' at 'null' in 'null'\n",
      "2025-12-02T14:14:38.673350Z Thread-3 ERROR Reconfiguration failed: No configuration found for '761badbc' at 'null' in 'null'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_config.TableConfig at 0x7efc39710f10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import get_env\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.table import StreamTableEnvironment\n",
    "\n",
    "env = get_env.get_remote_env()\n",
    "t_env = StreamTableEnvironment.create(env)\n",
    "\n",
    "\n",
    "conf = t_env.get_config().get_configuration()\n",
    " \n",
    "# === Python Exec Location ===\n",
    "conf.set_string(\"python.executable\", \"/usr/bin/python3\")\n",
    "conf.set_string(\"pipeline.jars\", \"file:///opt/flink/plugins/gs-fs-hadoop/flink-gs-fs-hadoop-1.20.2.jar\")  # client-side path\n",
    "\n",
    "# === Allow fallback to Hadoop FS for gs:// and s3:// ===\n",
    "conf.set_string(\"fs.allowed-fallback-filesystems\", \"hadoop\")\n",
    "t_env.get_config().set(\"parallelism.default\", \"1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b07801f-df65-4d40-b941-2e5a108f1639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dae96f8e6620c3e0ac95ff1e657236ab\n",
      "<Row(1, 'hi')>\n",
      "<Row(2, 'there')>\n"
     ]
    }
   ],
   "source": [
    "# --- Create an Iceberg Hadoop catalog backed by MinIO (no Hive required) ---\n",
    "# Bucket 'warehouse' must already exist; subpath 'iceberg' will be created as needed\n",
    "\n",
    "t_env.execute_sql(\"DROP CATALOG IF EXISTS local_ice\")\n",
    "\n",
    "t_env.execute_sql(\"\"\"\n",
    "CREATE CATALOG local_ice WITH (\n",
    "  'type' = 'iceberg',\n",
    "  'catalog-type' = 'hadoop',\n",
    "  'warehouse' = 'gs://gks-datalake/warehouse',\n",
    "  'property-version' = '1'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Use the catalog + create/use a database\n",
    "t_env.execute_sql(\"USE CATALOG local_ice\")\n",
    "t_env.execute_sql(\"CREATE DATABASE IF NOT EXISTS db\")\n",
    "t_env.execute_sql(\"USE db\")\n",
    "\n",
    "# --- Create an Iceberg table (format v2 recommended) ---\n",
    "t_env.execute_sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hello (\n",
    "  id  INT,\n",
    "  txt STRING\n",
    ") WITH (\n",
    "  'format-version' = '2'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Write some data (INSERT INTO is streaming; this returns a TableResult)\n",
    "t_env.execute_sql(\"INSERT INTO hello VALUES (1,'hi'), (2,'there')\").wait()\n",
    "\n",
    "# Read it back (TableResult prints to stdout if you collect())\n",
    "# For quick demo: do a SELECT and print the first few rows\n",
    "res = t_env.execute_sql(\"SELECT * FROM hello\")\n",
    "print(res.get_job_client().get_job_id())  # optional: show job id\n",
    "for i, row in enumerate(res.collect()):\n",
    "    print(row)\n",
    "    if i >= 9:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18654b3d-ce7c-4e7e-bb6d-6a89a8d4db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3876580c0dca5fae301c3aea9413a039\n",
      "<Row(1, 'hi')>\n",
      "<Row(2, 'there')>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read it back (TableResult prints to stdout if you collect())\n",
    "# For quick demo: do a SELECT and print the first few rows\n",
    "res = t_env.execute_sql(\"SELECT * FROM hello\")\n",
    "print(res.get_job_client().get_job_id())  # optional: show job id\n",
    "for i, row in enumerate(res.collect()):\n",
    "    print(row)\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b13cb5-abf7-4cb5-acd2-206d237e1f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|    catalog name |\n",
      "+-----------------+\n",
      "| default_catalog |\n",
      "|       local_ice |\n",
      "+-----------------+\n",
      "2 rows in set\n"
     ]
    }
   ],
   "source": [
    "t_env.execute_sql(\"SHOW CATALOGS\").print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf2e348-84c6-4bfd-8484-17b4ace20225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "| database name |\n",
      "+---------------+\n",
      "|            db |\n",
      "+---------------+\n",
      "1 row in set\n"
     ]
    }
   ],
   "source": [
    "t_env.execute_sql(\"SHOW DATABASES in local_ice\").print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630eac88-aa40-4644-bdee-ca3b5ba9490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "| table name |\n",
      "+------------+\n",
      "|      hello |\n",
      "+------------+\n",
      "1 row in set\n"
     ]
    }
   ],
   "source": [
    "t_env.execute_sql(\"SHOW TABLES in db\").print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d82d2c0-97b3-4741-ac54-5f04a9204e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------------------+\n",
      "| op |          id |                            txt |\n",
      "+----+-------------+--------------------------------+\n",
      "| +I |           1 |                             hi |\n",
      "| +I |           2 |                          there |\n",
      "+----+-------------+--------------------------------+\n",
      "2 rows in set\n"
     ]
    }
   ],
   "source": [
    "t_env.execute_sql(\"select * from hello\").print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efca5003-bf38-46e3-adfb-f9042ad8ef80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------------------+\n",
      "| op |          id |                            txt |\n",
      "+----+-------------+--------------------------------+\n",
      "| +I |           1 |                             hi |\n",
      "| +I |           2 |                          there |\n",
      "+----+-------------+--------------------------------+\n",
      "2 rows in set\n"
     ]
    }
   ],
   "source": [
    "t_env.execute_sql(\"select * from local_ice.db.hello\").print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f066ffd4-477e-4965-b5a3-994738b6df74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
