{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f2d8f1-f46c-4518-ba3a-745345c5efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyflink.datastream import StreamExecutionEnvironment, RuntimeExecutionMode\n",
    "from pyflink.common.typeinfo import Types\n",
    "\n",
    "# SHIFT + ENTER to run the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64febb53-0588-49cd-9488-83fa167dcd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-01T07:00:40.698835Z main ERROR Reconfiguration failed: No configuration found for '12f40c25' at 'null' in 'null'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.12) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyflink.datastream.stream_execution_environment.StreamExecutionEnvironment at 0x7fb98eb77820>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Run by default on local environment, task manager, job manager runs inside single JVM\n",
    "# Local env means flink client, job manager, task manage embed into single JVM\n",
    "env = StreamExecutionEnvironment.get_execution_environment()\n",
    "env.set_runtime_mode(RuntimeExecutionMode.STREAMING)\n",
    "env.set_parallelism(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9912f96-853e-43d9-b377-8e4f4a3a72ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 20\n",
    "c = a + b # ACTION, NOT A LAZY, IMMEDIATE EXECUTION, RESULT AFTER EXPRESSION EXECUTED\n",
    "print (c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ab080c-6454-4bdf-a491-ea2d3fe85975",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(range(10))\n",
    "# Tiny pipeline\n",
    "# Flink is structured, need data type, schema\n",
    "# DS is  a reference to dataset in a remote, like a pointer , the data is not loaded inot TASK MANAGER, LAZY EVAL\n",
    "# PLANNING HAS NO COST (does not use the cluster), happens at Flink Client ie this notebook\n",
    "ds = env.from_collection(data, type_info=Types.INT())\n",
    "# LAZY EVAL, DOESNOT EXECUTE\n",
    "# we have numbers 1...to 9\n",
    "#  map - add 1 to each numners rang from 1 to 9   (1 + 1 = 2, 2 + 1 = , 3 + 1 = 4... 9 + 1 = 10), \n",
    "# TRANSFORMATION - map, case convertion, number convertions, foreignheit to celcius, km to miles, etc\n",
    "# TRANSFORMATION - input from map (2,3,4,..10), we filter only even number, we pick only 2,4,6,8,10m LAZY\n",
    "even = (ds\n",
    "        .map(lambda x: x + 1, output_type=Types.INT())\n",
    "        .filter(lambda x: x % 2 == 0))\n",
    "# did the x + 1, filter x $ 2 == 0 already executed ?? NO, transformation are LAZY, PLANNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613fed07-b7f6-4030-869b-2268cc1cbda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.datastream.data_stream.DataStreamSink at 0x7fb99150e830>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing to stdout just to have a running sink:\n",
    "even.print() # does not print, it create a simple DAG, discussed in next notebook\n",
    "\n",
    "# DATA FLOW\n",
    "# We have a data flow, we have input 1 to 9\n",
    "# then map add number 1 to input (2, 3..10)\n",
    "# the nwe filter only even from map function (2,4,6,8,10)\n",
    "\n",
    "# then print the result to stdoutput aslo known as SINK, also PART OF THE DATAFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5aef353-522e-41cf-aef5-c63583fed12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-01T07:00:43.051621Z Thread-3 ERROR Reconfiguration failed: No configuration found for '20fd5a83' at 'null' in 'null'\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyflink.common.job_execution_result.JobExecutionResult at 0x7fb962f1c7c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we run the DATA FLOW (load numbber -< appky map -> apply filter -> write to stdout),\n",
    "# job manager, task manager all shall be used\n",
    "# ACTION - uses teh cluster\n",
    "# pyflink-dag-demo-datastream - name of the log for tracking\n",
    "env.execute(\"pyflink-dag-demo-datastream\") # Action, execute the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013c5dbd-08b8-441b-9461-98f117953ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
