{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "824fe62d-5870-4017-a6cc-0bdec29a24d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyFlink DataStream DAG demo (Flink 1.20, Python)\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.common.typeinfo import Types\n",
    "import json\n",
    "\n",
    "import os\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.table import StreamTableEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4429992-8baa-4856-9269-6bd6de73faba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.datastream.stream_execution_environment.StreamExecutionEnvironment at 0x7fdb9f8d3160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DAG - Directed Acylic Graph, a chained operation for Data Flow\n",
    "# DAG consisted of pipeline and processors, processoros are nothing but logic applied\n",
    "\n",
    "env = StreamExecutionEnvironment.get_execution_environment()\n",
    "env.set_parallelism(1)\n",
    "\n",
    "# Optional: show every operator as a separate vertex (nice for DAG clarity)\n",
    "env.disable_operator_chaining()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f50685-99c5-422d-9fcf-3a45b091e05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"nodes\" : [ {\n",
      "    \"id\" : 1,\n",
      "    \"type\" : \"Source: Collection Source\",\n",
      "    \"pact\" : \"Data Source\",\n",
      "    \"contents\" : \"Source: Collection Source\",\n",
      "    \"parallelism\" : 1\n",
      "  }, {\n",
      "    \"id\" : 4,\n",
      "    \"type\" : \"Map, Filter\",\n",
      "    \"pact\" : \"Operator\",\n",
      "    \"contents\" : \"Map, Filter\",\n",
      "    \"parallelism\" : 1,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 1,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  } ]\n",
      "}\n",
      "\n",
      "Pretty:\n",
      " {\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"type\": \"Source: Collection Source\",\n",
      "      \"pact\": \"Data Source\",\n",
      "      \"contents\": \"Source: Collection Source\",\n",
      "      \"parallelism\": 1\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"type\": \"Map, Filter\",\n",
      "      \"pact\": \"Operator\",\n",
      "      \"contents\": \"Map, Filter\",\n",
      "      \"parallelism\": 1,\n",
      "      \"predecessors\": [\n",
      "        {\n",
      "          \"id\": 1,\n",
      "          \"ship_strategy\": \"FORWARD\",\n",
      "          \"side\": \"second\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tiny pipeline\n",
    "ds = env.from_collection(list(range(10)), type_info=Types.INT())\n",
    "even = (ds\n",
    "        .map(lambda x: x + 1, output_type=Types.INT())\n",
    "        .filter(lambda x: x % 2 == 0))\n",
    "\n",
    "# --- A) Print DAG/plan (JSON) to console without running the job ---\n",
    "plan_json = env.get_execution_plan()          # returns a JSON string\n",
    "print(plan_json)\n",
    "print(\"\\nPretty:\\n\", json.dumps(json.loads(plan_json), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43728ee3-ba23-4306-9420-28e1bc1c3416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"nodes\" : [ {\n",
      "    \"id\" : 1,\n",
      "    \"type\" : \"Source: Collection Source\",\n",
      "    \"pact\" : \"Data Source\",\n",
      "    \"contents\" : \"Source: Collection Source\",\n",
      "    \"parallelism\" : 1\n",
      "  }, {\n",
      "    \"id\" : 4,\n",
      "    \"type\" : \"Map, Filter\",\n",
      "    \"pact\" : \"Operator\",\n",
      "    \"contents\" : \"Map, Filter\",\n",
      "    \"parallelism\" : 1,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 1,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  }, {\n",
      "    \"id\" : 6,\n",
      "    \"type\" : \"Map, Filter\",\n",
      "    \"pact\" : \"Operator\",\n",
      "    \"contents\" : \"Map, Filter\",\n",
      "    \"parallelism\" : 1,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 1,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  }, {\n",
      "    \"id\" : 8,\n",
      "    \"type\" : \"Map, Filter\",\n",
      "    \"pact\" : \"Operator\",\n",
      "    \"contents\" : \"Map, Filter\",\n",
      "    \"parallelism\" : 1,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 1,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  }, {\n",
      "    \"id\" : 5,\n",
      "    \"type\" : \"Sink: Print to Std. Out\",\n",
      "    \"pact\" : \"Data Sink\",\n",
      "    \"contents\" : \"Sink: Print to Std. Out\",\n",
      "    \"parallelism\" : 1,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 6,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  }, {\n",
      "    \"id\" : 7,\n",
      "    \"type\" : \"Sink: Print to Std. Out\",\n",
      "    \"pact\" : \"Data Sink\",\n",
      "    \"contents\" : \"Sink: Print to Std. Out\",\n",
      "    \"parallelism\" : 1,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 8,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  } ]\n",
      "}\n",
      "\n",
      "Pretty:\n",
      " {\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"type\": \"Source: Collection Source\",\n",
      "      \"pact\": \"Data Source\",\n",
      "      \"contents\": \"Source: Collection Source\",\n",
      "      \"parallelism\": 1\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"type\": \"Map, Filter\",\n",
      "      \"pact\": \"Operator\",\n",
      "      \"contents\": \"Map, Filter\",\n",
      "      \"parallelism\": 1,\n",
      "      \"predecessors\": [\n",
      "        {\n",
      "          \"id\": 1,\n",
      "          \"ship_strategy\": \"FORWARD\",\n",
      "          \"side\": \"second\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"type\": \"Map, Filter\",\n",
      "      \"pact\": \"Operator\",\n",
      "      \"contents\": \"Map, Filter\",\n",
      "      \"parallelism\": 1,\n",
      "      \"predecessors\": [\n",
      "        {\n",
      "          \"id\": 1,\n",
      "          \"ship_strategy\": \"FORWARD\",\n",
      "          \"side\": \"second\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 8,\n",
      "      \"type\": \"Map, Filter\",\n",
      "      \"pact\": \"Operator\",\n",
      "      \"contents\": \"Map, Filter\",\n",
      "      \"parallelism\": 1,\n",
      "      \"predecessors\": [\n",
      "        {\n",
      "          \"id\": 1,\n",
      "          \"ship_strategy\": \"FORWARD\",\n",
      "          \"side\": \"second\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"type\": \"Sink: Print to Std. Out\",\n",
      "      \"pact\": \"Data Sink\",\n",
      "      \"contents\": \"Sink: Print to Std. Out\",\n",
      "      \"parallelism\": 1,\n",
      "      \"predecessors\": [\n",
      "        {\n",
      "          \"id\": 6,\n",
      "          \"ship_strategy\": \"FORWARD\",\n",
      "          \"side\": \"second\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"type\": \"Sink: Print to Std. Out\",\n",
      "      \"pact\": \"Data Sink\",\n",
      "      \"contents\": \"Sink: Print to Std. Out\",\n",
      "      \"parallelism\": 1,\n",
      "      \"predecessors\": [\n",
      "        {\n",
      "          \"id\": 8,\n",
      "          \"ship_strategy\": \"FORWARD\",\n",
      "          \"side\": \"second\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "2025-12-01T07:30:59.270200Z Thread-3 ERROR Reconfiguration failed: No configuration found for '79ae43' at 'null' in 'null'\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "6\n",
      "8\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyflink.common.job_execution_result.JobExecutionResult at 0x7fdb9f99f0d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- B) Run so you can see it on the Dashboard UI (http://localhost:8081) ---\n",
    "# Printing to stdout just to have a running sink:\n",
    "even.print()\n",
    "\n",
    "# now we can see sink in the data flow graph\n",
    "\n",
    "plan_json = env.get_execution_plan()          # returns a JSON string\n",
    "print(plan_json)\n",
    "print(\"\\nPretty:\\n\", json.dumps(json.loads(plan_json), indent=2))\n",
    "\n",
    "\n",
    "env.execute(\"pyflink-dag-demo-datastream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f83ec2-72b8-46fd-84e4-a0d1d2120307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyflink.datastream.functions import MapFunction, RuntimeContext\n",
    "from pyflink.common.typeinfo import Types\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63f7c85d-21a5-4bd1-9c3a-65d50f4e09f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS Demonstration to explain how it works internally in Task manager\n",
    "from pyflink.common.typeinfo import Types\n",
    "import socket, os, threading, json\n",
    "\n",
    "class WhoAmI(MapFunction):\n",
    "    def open(self, rc: RuntimeContext):\n",
    "        self.subtask = rc.get_index_of_this_subtask()\n",
    "        self.host = socket.gethostname()\n",
    "    def map(self, x):\n",
    "        return f\"host={self.host} subtask={self.subtask} value={x}\"\n",
    "\n",
    "\n",
    "class Inspect(MapFunction):\n",
    "    def open(self, rc: RuntimeContext):\n",
    "        # RuntimeContext-based task info\n",
    "        self.task_name = rc.get_task_name()                       # e.g. \"Map\"\n",
    "        self.task_name_ws = rc.get_task_name_with_subtasks()      # e.g. \"Map (2/3)\"\n",
    "        self.subtask_index = rc.get_index_of_this_subtask()       # 0..p-1\n",
    "        self.parallelism = rc.get_number_of_parallel_subtasks()   # p\n",
    "        self.attempt = rc.get_attempt_number()                    # 0 on first try\n",
    "\n",
    "        # Environment/process info\n",
    "        self.host = socket.gethostname()                          # TM host/container\n",
    "        self.pid = os.getpid()                                    # Python worker PID\n",
    "        self.thread_id = threading.get_ident()                    # Python thread id\n",
    "\n",
    "    def map(self, x):\n",
    "        return json.dumps({\n",
    "            \"value\": x,\n",
    "            \"host\": self.host,\n",
    "            \"pid\": self.pid,\n",
    "            \"thread_id\": self.thread_id,\n",
    "            \"task_name\": self.task_name,\n",
    "            \"task_name_with_subtasks\": self.task_name_ws,\n",
    "            \"subtask_index\": self.subtask_index,\n",
    "            \"parallelism\": self.parallelism,\n",
    "            \"attempt\": self.attempt\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69b0136d-a7fe-49de-97fa-74811beb7bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"nodes\" : [ {\n",
      "    \"id\" : 109,\n",
      "    \"type\" : \"Source: Collection Source\",\n",
      "    \"pact\" : \"Data Source\",\n",
      "    \"contents\" : \"Source: Collection Source\",\n",
      "    \"parallelism\" : 1\n",
      "  }, {\n",
      "    \"id\" : 110,\n",
      "    \"type\" : \"_stream_key_by_map_operator\",\n",
      "    \"pact\" : \"Operator\",\n",
      "    \"contents\" : \"_stream_key_by_map_operator\",\n",
      "    \"parallelism\" : 1,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 109,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  }, {\n",
      "    \"id\" : 112,\n",
      "    \"type\" : \"Map\",\n",
      "    \"pact\" : \"Operator\",\n",
      "    \"contents\" : \"Map\",\n",
      "    \"parallelism\" : 3,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 110,\n",
      "      \"ship_strategy\" : \"HASH\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  }, {\n",
      "    \"id\" : 113,\n",
      "    \"type\" : \"Sink: Print to Std. Out\",\n",
      "    \"pact\" : \"Data Sink\",\n",
      "    \"contents\" : \"Sink: Print to Std. Out\",\n",
      "    \"parallelism\" : 3,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 112,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  } ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyflink.common.job_execution_result.JobExecutionResult at 0x7f932534a8f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = get_env.get_remote_env()\n",
    "env.set_parallelism(3)\n",
    "t_env = StreamTableEnvironment.create(env)\n",
    "t_env.get_config().set(\"parallelism.default\", \"3\")\n",
    "env.disable_operator_chaining()  \n",
    "\n",
    "# pretend \"splits\": 3 buckets -> observe routing differences below\n",
    "src = env.from_collection([(\"a\",1),(\"b\",2),(\"c\",3),(\"a\",4),(\"b\",5),(\"c\",6)],\n",
    "                          type_info=Types.TUPLE([Types.STRING(), Types.INT()]))\n",
    "\n",
    "# key_by uses hash partitioning subtask = f(hash(key), maxParallelism, parallelism) via key-groups.\n",
    "# key_by same key-group â†’ one subtask\n",
    "# Try different partitioners one by one to SEE how routing changes:\n",
    "stream = src.key_by(lambda kv: kv[0])          # KEYED (by first field)\n",
    " \n",
    "stream.map(Inspect(), output_type=Types.STRING()).set_parallelism(3).print()\n",
    "print(env.get_execution_plan())\n",
    "\n",
    "env.execute(\"dag-partition-demo-keyby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0fa5544-e583-4fc1-bf2a-747cb28eede4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"nodes\" : [ {\n",
      "    \"id\" : 69,\n",
      "    \"type\" : \"Source: Collection Source\",\n",
      "    \"pact\" : \"Data Source\",\n",
      "    \"contents\" : \"Source: Collection Source\",\n",
      "    \"parallelism\" : 1\n",
      "  }, {\n",
      "    \"id\" : 71,\n",
      "    \"type\" : \"Map\",\n",
      "    \"pact\" : \"Operator\",\n",
      "    \"contents\" : \"Map\",\n",
      "    \"parallelism\" : 3,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 69,\n",
      "      \"ship_strategy\" : \"REBALANCE\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  }, {\n",
      "    \"id\" : 72,\n",
      "    \"type\" : \"Sink: Print to Std. Out\",\n",
      "    \"pact\" : \"Data Sink\",\n",
      "    \"contents\" : \"Sink: Print to Std. Out\",\n",
      "    \"parallelism\" : 3,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 71,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  } ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyflink.common.job_execution_result.JobExecutionResult at 0x7f93253498a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = get_env.get_remote_env()\n",
    "env.set_parallelism(3)\n",
    "t_env = StreamTableEnvironment.create(env)\n",
    "t_env.get_config().set(\"parallelism.default\", \"3\")\n",
    "env.disable_operator_chaining()  \n",
    "\n",
    "\n",
    "# pretend \"splits\": 3 buckets -> observe routing differences below\n",
    "src = env.from_collection([(\"a\",1),(\"b\",2),(\"c\",3),(\"a\",4),(\"b\",5),(\"c\",6)],\n",
    "                          type_info=Types.TUPLE([Types.STRING(), Types.INT()]))\n",
    " \n",
    "stream = src.rebalance()                     # round-robin\n",
    " \n",
    "\n",
    "\n",
    "# stream.map(WhoAmI(), output_type=Types.STRING()).print()\n",
    "stream.map(Inspect(), output_type=Types.STRING()).set_parallelism(3).print()\n",
    "print(env.get_execution_plan())\n",
    "\n",
    "env.execute(\"dag-partition-rebalance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcbcee9b-9644-47dc-b9fd-45dbd5dfb185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"nodes\" : [ {\n",
      "    \"id\" : 75,\n",
      "    \"type\" : \"Source: Collection Source\",\n",
      "    \"pact\" : \"Data Source\",\n",
      "    \"contents\" : \"Source: Collection Source\",\n",
      "    \"parallelism\" : 1\n",
      "  }, {\n",
      "    \"id\" : 77,\n",
      "    \"type\" : \"Map\",\n",
      "    \"pact\" : \"Operator\",\n",
      "    \"contents\" : \"Map\",\n",
      "    \"parallelism\" : 6,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 75,\n",
      "      \"ship_strategy\" : \"RESCALE\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  }, {\n",
      "    \"id\" : 78,\n",
      "    \"type\" : \"Sink: Print to Std. Out\",\n",
      "    \"pact\" : \"Data Sink\",\n",
      "    \"contents\" : \"Sink: Print to Std. Out\",\n",
      "    \"parallelism\" : 3,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 77,\n",
      "      \"ship_strategy\" : \"REBALANCE\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  } ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyflink.common.job_execution_result.JobExecutionResult at 0x7f932251c160>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = get_env.get_remote_env()\n",
    "env.set_parallelism(3)\n",
    "t_env = StreamTableEnvironment.create(env)\n",
    "t_env.get_config().set(\"parallelism.default\", \"3\")\n",
    "env.disable_operator_chaining()  \n",
    "\n",
    "\n",
    "# pretend \"splits\": 3 buckets -> observe routing differences below\n",
    "src = env.from_collection([(\"a\",1),(\"b\",2),(\"c\",3),(\"a\",4),(\"b\",5),(\"c\",6)],\n",
    "                          type_info=Types.TUPLE([Types.STRING(), Types.INT()]))\n",
    "\n",
    " \n",
    "stream = src.rescale()                       # partial round-robin (upstream->subset downstream)\n",
    " \n",
    "\n",
    "stream.map(Inspect(), output_type=Types.STRING()).set_parallelism(6).print()\n",
    "print(env.get_execution_plan())\n",
    "\n",
    "env.execute(\"dag-partition-rescale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8c3844b-459f-485a-8d76-060a2e4dca1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"nodes\" : [ {\n",
      "    \"id\" : 81,\n",
      "    \"type\" : \"Source: Collection Source\",\n",
      "    \"pact\" : \"Data Source\",\n",
      "    \"contents\" : \"Source: Collection Source\",\n",
      "    \"parallelism\" : 1\n",
      "  }, {\n",
      "    \"id\" : 83,\n",
      "    \"type\" : \"Map\",\n",
      "    \"pact\" : \"Operator\",\n",
      "    \"contents\" : \"Map\",\n",
      "    \"parallelism\" : 3,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 81,\n",
      "      \"ship_strategy\" : \"SHUFFLE\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  }, {\n",
      "    \"id\" : 84,\n",
      "    \"type\" : \"Sink: Print to Std. Out\",\n",
      "    \"pact\" : \"Data Sink\",\n",
      "    \"contents\" : \"Sink: Print to Std. Out\",\n",
      "    \"parallelism\" : 3,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 83,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  } ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyflink.common.job_execution_result.JobExecutionResult at 0x7f932254ada0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = get_env.get_remote_env()\n",
    "env.set_parallelism(3)\n",
    "t_env = StreamTableEnvironment.create(env)\n",
    "t_env.get_config().set(\"parallelism.default\", \"3\")\n",
    "env.disable_operator_chaining()  \n",
    "\n",
    "\n",
    "# pretend \"splits\": 3 buckets -> observe routing differences below\n",
    "src = env.from_collection([(\"a\",1),(\"b\",2),(\"c\",3),(\"a\",4),(\"b\",5),(\"c\",6)],\n",
    "                          type_info=Types.TUPLE([Types.STRING(), Types.INT()]))\n",
    "\n",
    "\n",
    "stream = src.shuffle()                       # random\n",
    "\n",
    "stream.map(Inspect(), output_type=Types.STRING()).set_parallelism(3).print()\n",
    "print(env.get_execution_plan())\n",
    "\n",
    "env.execute(\"dag-partition-shuffle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93317a05-0999-4f11-88bc-79ed0ee6bc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"nodes\" : [ {\n",
      "    \"id\" : 49,\n",
      "    \"type\" : \"Source: Collection Source\",\n",
      "    \"pact\" : \"Data Source\",\n",
      "    \"contents\" : \"Source: Collection Source\",\n",
      "    \"parallelism\" : 1\n",
      "  }, {\n",
      "    \"id\" : 51,\n",
      "    \"type\" : \"Map\",\n",
      "    \"pact\" : \"Operator\",\n",
      "    \"contents\" : \"Map\",\n",
      "    \"parallelism\" : 3,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 49,\n",
      "      \"ship_strategy\" : \"BROADCAST\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  }, {\n",
      "    \"id\" : 52,\n",
      "    \"type\" : \"Sink: Print to Std. Out\",\n",
      "    \"pact\" : \"Data Sink\",\n",
      "    \"contents\" : \"Sink: Print to Std. Out\",\n",
      "    \"parallelism\" : 3,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 51,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  } ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyflink.common.job_execution_result.JobExecutionResult at 0x7f93279928f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = get_env.get_remote_env()\n",
    "env.set_parallelism(3)\n",
    "t_env = StreamTableEnvironment.create(env)\n",
    "t_env.get_config().set(\"parallelism.default\", \"3\")\n",
    "env.disable_operator_chaining()  \n",
    "\n",
    "\n",
    "# pretend \"splits\": 3 buckets -> observe routing differences below\n",
    "src = env.from_collection([(\"a\",1),(\"b\",2),(\"c\",3),(\"a\",4),(\"b\",5),(\"c\",6)],\n",
    "                          type_info=Types.TUPLE([Types.STRING(), Types.INT()]))\n",
    "\n",
    "stream = src.broadcast()                     # duplicates to all downstream subtasks\n",
    "\n",
    "stream.map(Inspect(), output_type=Types.STRING()).set_parallelism(3).print()\n",
    "print(env.get_execution_plan())\n",
    "\n",
    "env.execute(\"dag-partition-broadcast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10b47d86-1f1d-42b7-9f86-c25127298519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"nodes\" : [ {\n",
      "    \"id\" : 87,\n",
      "    \"type\" : \"Source: Collection Source\",\n",
      "    \"pact\" : \"Data Source\",\n",
      "    \"contents\" : \"Source: Collection Source\",\n",
      "    \"parallelism\" : 1\n",
      "  }, {\n",
      "    \"id\" : 88,\n",
      "    \"type\" : \"_stream_key_by_map_operator\",\n",
      "    \"pact\" : \"Operator\",\n",
      "    \"contents\" : \"_stream_key_by_map_operator\",\n",
      "    \"parallelism\" : 1,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 87,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  }, {\n",
      "    \"id\" : 90,\n",
      "    \"type\" : \"_partition_custom_map_operator\",\n",
      "    \"pact\" : \"Operator\",\n",
      "    \"contents\" : \"_partition_custom_map_operator\",\n",
      "    \"parallelism\" : 1,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 87,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  }, {\n",
      "    \"id\" : 98,\n",
      "    \"type\" : \"_keyed_stream_values_operator, Map\",\n",
      "    \"pact\" : \"Operator\",\n",
      "    \"contents\" : \"_keyed_stream_values_operator, Map\",\n",
      "    \"parallelism\" : 3,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 90,\n",
      "      \"ship_strategy\" : \"CUSTOM\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  }, {\n",
      "    \"id\" : 94,\n",
      "    \"type\" : \"Sink: Print to Std. Out\",\n",
      "    \"pact\" : \"Data Sink\",\n",
      "    \"contents\" : \"Sink: Print to Std. Out\",\n",
      "    \"parallelism\" : 3,\n",
      "    \"predecessors\" : [ {\n",
      "      \"id\" : 98,\n",
      "      \"ship_strategy\" : \"FORWARD\",\n",
      "      \"side\" : \"second\"\n",
      "    } ]\n",
      "  } ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyflink.common.job_execution_result.JobExecutionResult at 0x7f93245434c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = get_env.get_remote_env()\n",
    "env.set_parallelism(3)\n",
    "t_env = StreamTableEnvironment.create(env)\n",
    "t_env.get_config().set(\"parallelism.default\", \"3\")\n",
    "env.disable_operator_chaining()  \n",
    "\n",
    "from pyflink.datastream.functions import Partitioner\n",
    "\n",
    "\n",
    "# pretend \"splits\": 3 buckets -> observe routing differences below\n",
    "src = env.from_collection([(\"a\",1),(\"b\",2),(\"c\",3),(\"a\",4),(\"b\",5),(\"c\",6)],\n",
    "                          type_info=Types.TUPLE([Types.STRING(), Types.INT()]))\n",
    "\n",
    "# Try different partitioners one by one to SEE how routing changes:\n",
    "stream = src.key_by(lambda kv: kv[0])          # KEYED (by first field)\n",
    "\n",
    "\n",
    "class OddEvenPartitioner(Partitioner):\n",
    "    def partition(self, key, num_partitions: int) -> int:\n",
    "        # send even keys to subtask 0, odd to subtask 1 (mod to be safe)\n",
    "        return (key % 2) % num_partitions\n",
    "\n",
    "# choose which part of the record becomes the \"key\" fed to the partitioner:\n",
    "# custom partition based on key or value\n",
    "stream = src.partition_custom(OddEvenPartitioner(), key_selector=lambda r: r[1])\n",
    "\n",
    " \n",
    "stream.map(Inspect(), output_type=Types.STRING()).set_parallelism(3).print()\n",
    "print(env.get_execution_plan())\n",
    "\n",
    "env.execute(\"custom-partition-demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00b1132-0c43-4b56-aed1-c4889673d9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
