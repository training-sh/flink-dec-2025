{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f78ee-6635-44b5-80d9-91568d358320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.table import StreamTableEnvironment\n",
    "\n",
    "from pyflink.table import EnvironmentSettings, TableEnvironment\n",
    "\n",
    "import get_env\n",
    "env = get_env.get_remote_env()\n",
    "t_env = StreamTableEnvironment.create(env)\n",
    "\n",
    "conf = t_env.get_config().get_configuration()\n",
    " \n",
    "\n",
    "# === Python Exec Location ===\n",
    "conf.set_string(\"python.executable\", \"/usr/bin/python3\")\n",
    "conf.set_string(\"pipeline.jars\", \"file:///opt/flink/plugins/gs-fs-hadoop/flink-gs-fs-hadoop-1.20.2.jar\")  # client-side path\n",
    "\n",
    "# === Allow fallback to Hadoop FS for gs:// and s3:// ===\n",
    "conf.set_string(\"fs.allowed-fallback-filesystems\", \"hadoop\")\n",
    " \n",
    "\n",
    "t_env.get_config().set(\"parallelism.default\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ace1a-7c1b-4698-922e-65e57ff6de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = t_env.get_config().get_configuration()\n",
    "conf.set_string(\"fs.allowed-fallback-filesystems\", \"hadoop\")\n",
    "conf.set_string(\"fs.gs.project.id\", \"flink-demo-470113\")\n",
    "conf.set_string(\"fs.gs.auth.service.account.json.keyfile\", \"/etc/gcp/key.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50d581-4767-44fb-b55a-5f58c5e129e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ A: Catalog (Hadoop-style, backing files in GCS) -------------\n",
    "t_env.execute_sql(\"DROP CATALOG IF EXISTS ordercat\")\n",
    "\n",
    "t_env.execute_sql(\"\"\"\n",
    "CREATE CATALOG IF NOT EXISTS ordercat WITH (\n",
    "  'type' = 'iceberg',\n",
    "  'catalog-type' = 'hadoop',\n",
    "  -- GCS path for metadata/warehouse; ensure the bucket exists and Flink has write access\n",
    "  'warehouse' = 'gs://gks-datalake/iceberg-warehouse/',\n",
    "  'property-version' = '1'\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Tell Flink to use it\n",
    "# t_env.execute_sql(\"USE CATALOG movielens\")\n",
    "t_env.execute_sql(\"CREATE DATABASE IF NOT EXISTS ordercat.orderdb\")\n",
    "# t_env.execute_sql(\"USE gold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562f5091-aa67-4bb1-91a7-9195ade432b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_env.execute_sql(\"\"\"\n",
    "DROP TABLE IF  EXISTS ordercat.orderdb.shipments\n",
    "\"\"\").wait()\n",
    "\n",
    "\"\"\"\n",
    "-- features shown:\n",
    "--  - format-version = 2 (row-level deletes/updates support)\n",
    "--  - partitioned by day(customer use-case)\n",
    "--  - primary key declared (NOT ENFORCED) â€” helpful for upsert semantics\n",
    "--  - table properties example: enable upsert by default, set snapshot retention hints\n",
    "\"\"\"\n",
    "\n",
    "t_env.execute_sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS ordercat.orderdb.shipments (\n",
    "  shipment_id      BIGINT,\n",
    "  origin           STRING,\n",
    "  destination      STRING,\n",
    "  shipped_at       TIMESTAMP(3),\n",
    "  weight_kg        DOUBLE,\n",
    "  PRIMARY KEY (shipment_id) NOT ENFORCED\n",
    ")\n",
    "WITH (\n",
    "  'format-version' = '2',\n",
    "  'write.upsert.enabled' = 'true',\n",
    "  'snapshot.retention.days' = '7',\n",
    "  'write.metadata.delete-after-commit' = 'false'\n",
    ");\n",
    "\"\"\").wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9703aa86-3e9a-4b12-800c-91103e263dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = t_env.sql_query(\"SELECT * FROM ordercat.orderdb.shipments\")\n",
    "\n",
    "result.execute().print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec093e-5fc8-4a9d-9c47-a49ebe77a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# streaming INSERT (returns a TableResult)\n",
    "t_env.execute_sql(\"\"\"\n",
    "INSERT INTO ordercat.orderdb.shipments (shipment_id, origin, destination, shipped_at, weight_kg)\n",
    "VALUES\n",
    "  (1001, 'BLR', 'DEL', TIMESTAMP '2025-11-01 08:12:00', 12.5),\n",
    "  (1002, 'MGR', 'HYD', TIMESTAMP '2025-11-02 09:30:00', 7.75)\n",
    "\"\"\").wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749efefc-ee11-4b1a-a08a-a76f4bcb24ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = t_env.sql_query(\"SELECT * FROM ordercat.orderdb.shipments\")\n",
    "\n",
    "result.execute().print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd53ecf-6a8d-471b-87c2-0b042264c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW CREATE TABLE (Flink will print DDL)\n",
    "res = t_env.execute_sql(\"SHOW CREATE TABLE ordercat.orderdb.shipments\")\n",
    "for r in res.collect():\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c68e565-0cb3-4195-95b4-f4777c5b340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_env.execute_sql(\"\"\"\n",
    "DROP TEMPORARY VIEW IF EXISTS upsert_stage\n",
    "\"\"\").wait()\n",
    "\n",
    "t_env.execute_sql(\"\"\"\n",
    "CREATE TEMPORARY VIEW upsert_stage AS\n",
    "SELECT * FROM (\n",
    "    VALUES\n",
    "        (1001, 'BLR', 'PUNE', TIMESTAMP '2025-11-01 08:12:00', 12.0),\n",
    "         (1003, 'MYS', 'BOM', TIMESTAMP '2025-11-02 09:30:00', 7.75)\n",
    ") AS t (shipment_id, origin, destination, shipped_at, weight_kg)\n",
    "\"\"\").wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b92c8-c8b1-48ad-b740-10ae0e78ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = t_env.sql_query(\"SELECT * FROM upsert_stage\")\n",
    "\n",
    "result.execute().print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06537fe8-648a-4e93-9156-1e38e46deed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works only with iceberg version 2 \n",
    "# if the rows matched, it updates else insert\n",
    "# king of merge, but no delete or update specific fields, \n",
    "# no exclude/include fields like SPARK/DATABRICKS\n",
    "t_env.execute_sql(\"\"\"\n",
    "INSERT INTO ordercat.orderdb.shipments\n",
    "/*+ OPTIONS('upsert-enabled'='true') */\n",
    "SELECT shipment_id, origin, destination, shipped_at, weight_kg\n",
    "FROM upsert_stage\n",
    "\"\"\").wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00785474-a714-4830-9e25-7e6ac0bd25b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = t_env.sql_query(\"SELECT * FROM ordercat.orderdb.shipments\")\n",
    "\n",
    "result.execute().print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31ad4f-62aa-43e0-a967-918616ccc536",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_env.execute_sql(\"\"\"\n",
    "DROP TEMPORARY VIEW IF EXISTS upsert_stage\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032d24a-1a9d-44a3-b14d-7eb46fe9a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW SNAPSHOTS\n",
    "# special table, <actual-tablename>$snapshots\n",
    "# $snapshots is keyword\n",
    "# Like history\n",
    "# backtick ` not a single quote. it preserve exact match\n",
    "result = t_env.sql_query(\"SELECT * FROM ordercat.orderdb.`shipments$snapshots`\")\n",
    "\n",
    "result.execute().print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a3657-d364-4a93-a315-7f6e575d75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same snapshots with specific columns, same like previous cell, reduced columns\n",
    "result = t_env.sql_query(\"\"\"\n",
    "SELECT snapshot_id,\n",
    "       parent_id,\n",
    "       committed_at,\n",
    "       operation,\n",
    "       summary\n",
    "       FROM ordercat.orderdb.`shipments$snapshots`;\n",
    "\"\"\")\n",
    "\n",
    "result.execute().print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7318e-1886-418b-b715-4d56f76cdd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Iceberg history system table\n",
    "\n",
    "result = t_env.sql_query(\"\"\"\n",
    "SELECT * \n",
    "FROM ordercat.orderdb.`shipments$history`\n",
    "\"\"\")\n",
    "\n",
    "result.execute().print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd2f35-168a-4462-b135-e5d7f7981eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCUSS: What is diffrence between snapshots and history?\n",
    "# SNAPSHOT can be removed like expired, retention policies, manual clean up\n",
    "# history is maintained in the meta data directory, available always\n",
    "# if snapshot removed, we CANNOT do ROLLBACK or TIME TRAVEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17be1a1e-f911-4ed2-b6ef-974ea84b5f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+----------------------+----------------------------+--------------------------------+--------------------------------+\n",
      "| op |          snapshot_id |            parent_id |               committed_at |                      operation |                        summary |\n",
      "+----+----------------------+----------------------+----------------------------+--------------------------------+--------------------------------+\n",
      "| +I |   749072624420771859 |               <NULL> | 2025-12-02 16:57:40.086000 |                      overwrite | {added-delete-files=1, flin... |\n",
      "| +I |  1459376408147079364 |   749072624420771859 | 2025-12-02 17:01:34.118000 |                      overwrite | {added-delete-files=1, flin... |\n",
      "+----+----------------------+----------------------+----------------------------+--------------------------------+--------------------------------+\n",
      "2 rows in set\n"
     ]
    }
   ],
   "source": [
    "# Let us do time travel, time travel is all about what happend at particualr version\n",
    "# based on snapshots, NOT A ROLLBACK\n",
    "\n",
    "# get snapshots\n",
    "\n",
    "result = t_env.sql_query(\"\"\"\n",
    "SELECT snapshot_id, parent_id, committed_at, operation, summary\n",
    "FROM ordercat.orderdb.`shipments$snapshots`\n",
    "\"\"\")\n",
    "\n",
    "result.execute().print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7eb7d097-3025-444a-a021-dde8f9c2ae1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+--------------------------------+--------------------------------+----------------------------+--------------------------------+\n",
      "| op |          shipment_id |                         origin |                    destination |                 shipped_at |                      weight_kg |\n",
      "+----+----------------------+--------------------------------+--------------------------------+----------------------------+--------------------------------+\n",
      "| +I |                 1001 |                            BLR |                           PUNE | 2025-11-01 08:12:00.000000 |                           12.0 |\n",
      "| +I |                 1003 |                            MYS |                            BOM | 2025-11-02 09:30:00.000000 |                           7.75 |\n",
      "| +I |                 1002 |                            MGR |                            HYD | 2025-11-02 09:30:00.000000 |                           7.75 |\n",
      "+----+----------------------+--------------------------------+--------------------------------+----------------------------+--------------------------------+\n",
      "3 rows in set\n"
     ]
    }
   ],
   "source": [
    "# Time travel by snapshot id (exact)\n",
    "\n",
    "# replace snapshot id with the snapshot_id you found\n",
    "\n",
    "# replace snapshot id with value show about\n",
    "query = t_env.sql_query(\"\"\"\n",
    "   SELECT * FROM  ordercat.orderdb.shipments \n",
    "   /*+ OPTIONS('scan.snapshot-id'='749072624420771859') */;\n",
    "\"\"\")\n",
    "\n",
    "query.execute().print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7faf4ab5-49eb-4128-8c1e-12c4e7f22367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time ms 1764694200000\n",
      "+----+----------------------+--------------------------------+--------------------------------+----------------------------+--------------------------------+\n",
      "| op |          shipment_id |                         origin |                    destination |                 shipped_at |                      weight_kg |\n",
      "+----+----------------------+--------------------------------+--------------------------------+----------------------------+--------------------------------+\n",
      "| +I |                 1002 |                            MGR |                            HYD | 2025-11-02 09:30:00.000000 |                           7.75 |\n",
      "| +I |                 1001 |                            BLR |                           PUNE | 2025-11-01 08:12:00.000000 |                           12.0 |\n",
      "| +I |                 1003 |                            MYS |                            BOM | 2025-11-02 09:30:00.000000 |                           7.75 |\n",
      "+----+----------------------+--------------------------------+--------------------------------+----------------------------+--------------------------------+\n",
      "3 rows in set\n"
     ]
    }
   ],
   "source": [
    "# Time travel by timestamp\n",
    "\n",
    "# replace snapshot id with the snapshot_id you found\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def to_millis(dt_str):\n",
    "    \"\"\"\n",
    "    Convert 'YYYY-MM-DD HH:MM:SS[.ffffff]' to epoch milliseconds.\n",
    "    Assumes the input is in local time; set tzinfo as needed.\n",
    "    \"\"\"\n",
    "    # Try with microseconds first\n",
    "    try:\n",
    "        dt = datetime.strptime(dt_str, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    except ValueError:\n",
    "        # Fallback to seconds only\n",
    "        dt = datetime.strptime(dt_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # If your timestamp is UTC, set timezone here:\n",
    "    dt = dt.replace(tzinfo=timezone.utc)\n",
    "\n",
    "    # Convert to milliseconds\n",
    "    return int(dt.timestamp() * 1000)\n",
    "\n",
    "ts = to_millis(\"2025-12-02 16:50:00\")\n",
    "print (\"time ms\", ts)\n",
    "\n",
    "# replace snapshot id with value show about\n",
    "query = t_env.sql_query(f\"\"\"\n",
    "   SELECT * FROM  ordercat.orderdb.shipments \n",
    "   /*+ OPTIONS('scan.timestamp-millis'='{ts}') */;\n",
    "\"\"\")\n",
    "\n",
    "query.execute().print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e6af036-af93-4826-8dcd-9838c03093f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df816ef6-38d2-4ac5-946e-39b30f1b6690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
