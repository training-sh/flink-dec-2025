{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7614cbc-26ae-42ea-bc59-bc7e0e16097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, you need to add parquet to flink installation, follow instruction as per class session\n",
    "# you must take new Dockerfile on day2 github folder, then build image, then run the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91331cb3-3d54-4ef3-9ff6-178de09c02f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T03:18:30.914661Z main ERROR Reconfiguration failed: No configuration found for '63e31ee' at 'null' in 'null'\n",
      "2025-12-02T03:18:32.051116Z Thread-3 ERROR Reconfiguration failed: No configuration found for '65cad32d' at 'null' in 'null'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_config.TableConfig at 0x7f50117194b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.table import StreamTableEnvironment\n",
    "\n",
    "import get_env\n",
    "env = get_env.get_remote_env()\n",
    "t_env = StreamTableEnvironment.create(env)\n",
    "t_env.get_config().set(\"parallelism.default\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba90b87c-b637-4f59-a6c1-b937d66850c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.common.configuration.Configuration at 0x7f500e2daa70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = t_env.get_config().get_configuration()\n",
    "conf.set_string(\"fs.allowed-fallback-filesystems\", \"hadoop\")\n",
    "conf.set_string(\"fs.gs.project.id\", \"flink-demo-470113\")\n",
    "conf.set_string(\"fs.gs.auth.service.account.json.keyfile\", \"/etc/gcp/key.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422e3f78-9677-451c-81f5-e93309fa0be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Schema ===\n",
      "(\n",
      "  `userId` INT,\n",
      "  `movieId` INT,\n",
      "  `rating` DOUBLE,\n",
      "  `timestamp` BIGINT\n",
      ")\n",
      "=== Data ===\n",
      "+----+-------------+-------------+--------------------------------+----------------------+\n",
      "| op |      userId |     movieId |                         rating |            timestamp |\n",
      "+----+-------------+-------------+--------------------------------+----------------------+\n",
      "| +I |      <NULL> |      <NULL> |                         <NULL> |               <NULL> |\n",
      "| +I |           1 |           1 |                            4.0 |            964982703 |\n",
      "| +I |           1 |           3 |                            4.0 |            964981247 |\n",
      "| +I |           1 |           6 |                            4.0 |            964982224 |\n",
      "| +I |           1 |          47 |                            5.0 |            964983815 |\n",
      "+----+-------------+-------------+--------------------------------+----------------------+\n",
      "5 rows in set\n"
     ]
    }
   ],
   "source": [
    "t_env.execute_sql(\"\"\"\n",
    "CREATE TEMPORARY TABLE ratings_csv (\n",
    "  `userId` INT,\n",
    "  `movieId` INT,\n",
    "  `rating` DOUBLE,\n",
    "  `timestamp` BIGINT\n",
    ") WITH (\n",
    "  'connector' = 'filesystem',\n",
    "  'path' = 'gs://gk2-datalake/bronze/ratings/',\n",
    "  'format' = 'csv',\n",
    "  'csv.field-delimiter' = ',',\n",
    "  'csv.ignore-parse-errors' = 'true',\n",
    "  'csv.allow-comments' = 'false',\n",
    "  'csv.first-line-as-header' = 'true'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# 3) Get the table and print schema\n",
    "ratings_csv = t_env.from_path(\"ratings_csv\")\n",
    "print(\"=== Schema ===\")\n",
    "ratings_csv.print_schema()\n",
    "\n",
    "# 4) Print the data (bounded filesystem source -> will finish)\n",
    "print(\"=== Data ===\")\n",
    "\n",
    "limited = ratings_csv.limit(5)\n",
    "limited.execute().print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e5b6a10-b36d-4115-9b92-544446f1578b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_result.TableResult at 0x7f4fe372f7f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_env.execute_sql(\"DROP TABLE IF EXISTS ratings_parquet\")\n",
    "\n",
    "t_env.execute_sql(\"\"\"\n",
    "CREATE TABLE ratings_parquet (\n",
    "  `userId` INT,\n",
    "  `movieId` INT,\n",
    "  `rating` DOUBLE,\n",
    "  `timestamp` BIGINT\n",
    ") WITH (\n",
    "  'connector' = 'filesystem',\n",
    "  'path' = 'gs://gk2-datalake/silver/ratings/',\n",
    "  'format' = 'parquet'\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "955ceff2-053c-4ce3-bd42-3ef7b79097d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_result.TableResult at 0x7f4fe3737430>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REMAINER, flink-parquet-1.20.2.jar , parquet-hadoop-bundle-*.jar needed refer day2 Dockerfile\n",
    "\n",
    "# clean data, userId should not be null, and rating should be above 0.5\n",
    "\n",
    "t_env.execute_sql(\"\"\"\n",
    "INSERT INTO ratings_parquet\n",
    "SELECT userId, movieId, rating, `timestamp`\n",
    "FROM ratings_csv\n",
    "WHERE userId IS NOT NULL AND rating > 0.5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bb0055f-e1d7-4473-8f7e-3d5a5deac614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n"
     ]
    }
   ],
   "source": [
    "df = t_env.sql_query(\"\"\"\n",
    "    SELECT * FROM ratings_parquet LIMIT 5\n",
    "\"\"\").to_pandas()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cad5ab-842b-4bf5-b294-e006836fcab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
